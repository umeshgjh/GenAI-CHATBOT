# GenAI-CHATBOT
Intel Unnati Industrial Training Programme - Problem Statement - PS04 -  Introduction to GenAI and Simple LLM Inference on CPU and finetuning of LLM Model to create a Custom Chatbot

Creating a GitHub README file for your project involves summarizing the project, providing setup instructions, and guiding users on how to use your code effectively. Below is a template for your GitHub README file based on your project scenario:

---

# Custom Chatbot with Intel Extension for Transformers

This repository contains code to fine-tune a language model using the Intel Extension for Transformers and create a custom chatbot using the fine-tuned model.

## Requirements

- Python 3.12 (recommended)
- `pip` (Python package installer)
- `git` (for cloning the repository)

## Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/your-username/your-repository.git
   cd your-repository
   ```

2. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

   This will install necessary Python packages, including `transformers`, `torch`, and other dependencies required for fine-tuning and inference.

3. Install PyTorch (CPU version):

   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
   ```

   If you're using a GPU, install the appropriate CUDA version of PyTorch instead.

4. Install the Intel Extension for Transformers:

   ```bash
   pip install intel-extension-for-transformers
   ```

## Fine-tuning the Model

1. **Prepare Data**: Ensure your dataset is prepared as per the requirements of the `intel-extension-for-transformers`.

2. **Fine-tune the Model**:

   Use the provided script to fine-tune a language model using the Intel Extension for Transformers. Modify the paths and configurations as needed.

   ```bash
   python fine_tune_model.py
   ```

   Replace `fine_tune_model.py` with the actual script you use for fine-tuning.

## Using the Custom Chatbot

1. **Inference**:

   Load the fine-tuned model and tokenizer to interact with the chatbot. Adjust paths and configurations based on your fine-tuning output.

   ```python
   python chatbot.py
   ```

   This script allows users to interact with the chatbot using the command line. Type messages to the bot and receive responses generated by the fine-tuned model.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- This project uses the Intel Extension for Transformers for optimizing model performance.
- Parts of the code structure and README template may have been adapted from OpenAI's GPT-3 example.

## Troubleshooting

- If you encounter issues during installation or running the scripts, refer to the Troubleshooting section in the README or consult the project documentation.

---

### Notes:

- Replace placeholders (`your-username`, `your-repository`, `fine_tune_model.py`, `chatbot.py`, etc.) with actual values and filenames from your project.
- Include additional sections such as Usage Examples, Contributing Guidelines, or References as per your project's needs.
- Ensure to update the README as your project evolves, providing clear and concise instructions for users to understand and utilize your code effectively.

This template provides a structured approach to document your project on GitHub, helping users understand how to set up and use your custom chatbot built with the Intel Extension for Transformers.
