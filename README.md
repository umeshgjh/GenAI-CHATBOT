# GenAI-CHATBOT
Intel Unnati Industrial Training Programme - Problem Statement - PS04 -  Introduction to GenAI and Simple LLM Inference on CPU and finetuning of LLM Model to create a Custom Chatbot


# Custom Chatbot with Intel Extension for Transformers

This repository contains code to fine-tune a language model using the Intel Extension for Transformers and create a custom chatbot using the fine-tuned model.

## Requirements

- Python 3.12 (recommended)
- `pip` (Python package installer)
- `git` (for cloning the repository)

## Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/umeshgjh/GenAI-CHATBOT.git
   cd GenAI-CHATBOT
   ```

2. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

   This will install necessary Python packages, including `transformers`, `torch`, and other dependencies required for fine-tuning and inference.

3. Install PyTorch (CPU version):

   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
   ```

   If you're using a GPU, install the appropriate CUDA version of PyTorch instead.

4. Install the Intel Extension for Transformers:

   ```bash
   pip install intel-extension-for-transformers
   ```

## Fine-tuning the Model

1. **Prepare Data**: Ensure your dataset is prepared as per the requirements of the Intel Extension for Transformers.

2. **Fine-tune the Model**:

   Use the provided script to fine-tune a language model using the Intel Extension for Transformers. Modify the paths and configurations as needed.

   ```bash
   python finetune.py
   ```

## Using the Custom Chatbot

1. **Inference**:

   Load the fine-tuned model and tokenizer to interact with the chatbot. Adjust paths and configurations based on your fine-tuning output.

   ```bash
   python intel.py
   ```

   This script allows users to interact with the chatbot using the command line. Type messages to the bot and receive responses generated by the fine-tuned model.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- This project uses the Intel Extension for Transformers for optimizing model performance.

## Troubleshooting

If you encounter issues during installation or running the scripts, refer to the Troubleshooting section in the README or consult the project documentation.

---


